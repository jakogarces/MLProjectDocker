{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de datos\n",
    "\n",
    "En este paso crucial, preparamos nuestro conjunto de datos para la fase de modelado, asegurándonos de que nuestros datos estén en el formato apropiado para los algoritmos de aprendizaje automático. Las principales tareas en el preprocesamiento de datos incluyen codificar variables categóricas, escalar características numéricas y dividir los datos en conjuntos de entrenamiento y prueba. Aquí hay un desglose de cada tarea:\n",
    "\n",
    "### Codificación de variables categóricas\n",
    "\n",
    "Muchos modelos de aprendizaje automático requieren entrada numérica, por lo que las variables categóricas deben convertirse a un formato numérico. Usamos codificación one-hot para transformar las características categóricas ('Sex', 'BP', 'Cholesterol') en vectores binarios, que representan la presencia o ausencia de cada categoría con 0 y 1.\n",
    "\n",
    "### Dividir el conjunto de datos\n",
    "\n",
    "Dividimos nuestro conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba, lo que nos permite entrenar nuestros modelos en un subconjunto de datos y evaluar su desempeño en un conjunto independiente. Normalmente, asignamos el 80% de los datos para entrenamiento y el 20% para pruebas. Esta división garantiza que nuestro modelo pueda generalizarse bien a datos invisibles.\n",
    "\n",
    "### Escalado de funciones numéricas\n",
    "\n",
    "Finalmente, para garantizar que cada característica numérica contribuya por igual a la predicción del modelo, escalamos las características ('Age', 'Na', 'K'). Se aplica una escala estándar para normalizar los datos, estableciendo la media en 0 y la desviación estándar en 1. Este paso ayuda a mejorar la convergencia del modelo y su sensibilidad a los valores de las características.\n",
    "\n",
    "\n",
    "Al final de estos pasos de preprocesamiento, nuestros datos están limpios, formateados y listos para la etapa de modelado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries needed for EDA only\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# for the yeo-johnson transformation\n",
    "import scipy.stats as stats\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to save the trained scaler class\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'Drug.csv'\n",
    "data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train processed: \n",
      " [[ 0.49932185  0.52558168  0.61844831 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.48092384  1.27696108  1.36539494 ...  1.          1.\n",
      "   1.        ]\n",
      " [ 0.99012284 -1.50265424  1.20309138 ...  0.          1.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.97308114  1.35356617 -1.17559073 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.35822359  0.73394818 -0.02969257 ...  0.          2.\n",
      "   0.        ]\n",
      " [-1.03443126 -0.36541914  0.0031297  ...  0.          1.\n",
      "   0.        ]]\n",
      "(180, 7)\n",
      "X test processed: \n",
      " [[-0.54363027 -1.46208406 -0.21205104  0.          1.          1.\n",
      "   1.        ]\n",
      " [-1.77063276  1.14814076  0.2146949   1.          0.          0.\n",
      "   1.        ]\n",
      " [-1.64793251 -1.24114328  0.75267499  1.          0.          2.\n",
      "   1.        ]\n",
      " [ 0.86742259 -0.50042857  0.64279667  1.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.1312211   1.26657771 -1.39353961  0.          1.          1.\n",
      "   1.        ]\n",
      " [ 0.3766216   1.18780729 -0.23221894  0.          1.          0.\n",
      "   0.        ]\n",
      " [-1.64793251 -1.14528889 -1.50697697  1.          0.          0.\n",
      "   1.        ]\n",
      " [-1.03443126  0.39043585  0.44637151  1.          0.          2.\n",
      "   0.        ]\n",
      " [-0.17552952  1.35361731  0.97514329  0.          1.          0.\n",
      "   1.        ]\n",
      " [ 1.29687346 -0.74869178  1.43889196  1.          0.          2.\n",
      "   1.        ]\n",
      " [-0.97308114 -0.62986268 -0.07370039  0.          1.          0.\n",
      "   0.        ]\n",
      " [-1.52523226  0.95365285  1.09937076  1.          0.          1.\n",
      "   1.        ]\n",
      " [-0.42093002  1.29461623 -0.19352143  0.          1.          1.\n",
      "   0.        ]\n",
      " [-1.58658238 -1.55310481 -0.62761143  1.          0.          0.\n",
      "   0.        ]\n",
      " [ 1.54227396 -0.9348764   0.55997835  0.          1.          0.\n",
      "   0.        ]\n",
      " [-1.21848164  0.65254356 -0.51626429  0.          1.          2.\n",
      "   0.        ]\n",
      " [ 1.23552334 -0.54223486  0.34468463  0.          1.          0.\n",
      "   1.        ]\n",
      " [ 0.62202209 -1.61953112  1.14027148  0.          1.          2.\n",
      "   1.        ]\n",
      " [-0.78903077  0.2702172   1.43007909  1.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.56067197 -1.65521651 -1.66436567  0.          1.          2.\n",
      "   0.        ]]\n",
      "(20, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Defining the feature set and the target variable\n",
    "X = data.drop('Drug', axis=1)\n",
    "y = data['Drug']\n",
    "\n",
    "# Identifying numerical and categorical features\n",
    "numerical_features = ['Age', 'Na', 'K']\n",
    "categorical_features = ['Sex']\n",
    "ordinal_features = ['BP', 'Cholesterol']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Defining a column transformer with one-hot encoding for categorical features and scaling for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('ord', OrdinalEncoder(), ordinal_features)\n",
    "    ])\n",
    "\n",
    "# Fitting the transformer on the training data and transforming both the training and test data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"X train processed: \\n\" , X_train_processed)\n",
    "print(X_train_processed.shape)\n",
    "print(\"X test processed: \\n\" ,X_test_processed)\n",
    "print(X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construcción de modelos\n",
    "\n",
    "En esta fase, construiremos y entrenaremos cuatro modelos distintos de aprendizaje automático utilizando los algoritmos que hemos seleccionado: K-vecinos más cercanos (KNN), regresión logística, árboles de decisión y máquinas de vectores de soporte (SVM). Cada modelo se entrenará en nuestro conjunto de datos de entrenamiento y luego se evaluará en función de su rendimiento en el conjunto de datos de prueba. Los pasos para la construcción del modelo son los siguientes:\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "KNN hace predicciones para un nuevo punto de datos basándose en la etiqueta de mayoría entre sus 'k' vecinos más cercanos en el espacio de características. Es un algoritmo sencillo pero potente, particularmente eficaz para conjuntos de datos donde instancias similares tienen etiquetas similares.\n",
    "\n",
    "### Logistic Regression\n",
    "La regresión logística es un modelo estadístico que en su forma básica utiliza una función logística para modelar una variable dependiente binaria, aunque en formas más complejas se puede utilizar para modelar resultados multiclase. Es ampliamente utilizado para tareas de clasificación binaria.\n",
    "\n",
    "### Decision Trees\n",
    "Los árboles de decisión son estructuras similares a diagramas de flujo que utilizan métodos de ramificación para ilustrar todos los resultados posibles de una decisión. Son fáciles de entender e interpretar, pero pueden ser propensos a sobreajustarse, especialmente con conjuntos de datos complejos.\n",
    "\n",
    "### Support Vector Machines (SVM)\n",
    "Las SVM son un conjunto de métodos de aprendizaje supervisados que se utilizan para clasificación, regresión y detección de valores atípicos. Un modelo SVM es una representación de los ejemplos como puntos en el espacio, mapeados de modo que los ejemplos de las categorías separadas estén divididos por una brecha clara que sea lo más amplia posible.\n",
    "\n",
    "Después de entrenar cada modelo, evaluaremos su desempeño con los datos de prueba para comprender su efectividad. La métrica de precisión nos ayudará a determinar cuál es el modelo de mejor rendimiento entre los que hemos entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K-Nearest Neighbors': 0.85,\n",
       " 'Logistic Regression': 0.95,\n",
       " 'Decision Tree': 0.75,\n",
       " 'Support Vector Machine': 0.95}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the models\n",
    "knn = KNeighborsClassifier()\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Dictionary to store models and their respective accuracies\n",
    "models = {\n",
    "    'K-Nearest Neighbors': knn,\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Decision Tree': decision_tree,\n",
    "    'Support Vector Machine': svm\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracies\n",
    "accuracies = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies[model_name] = accuracy\n",
    "\n",
    "accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataTrain= pd.concat([pd.DataFrame(X_train_processed), y_train], axis=1)\n",
    "print(dataTrain)\n",
    "dataTest= pd.concat([pd.DataFrame(X_test_processed), y_test], axis=1)\n",
    "print(y_test)\n",
    "print(\"dataTest\")\n",
    "print(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from pycaret.datasets import get_data\n",
    "#DataAutoML = get_data(data) #Aquí cambias el Dataset que te haya tocado.\n",
    "ClassExperiment = ClassificationExperiment() #Instanciamos la clase\n",
    "# init setup on exp\n",
    "ClassExperiment.setup(data, target = 'Drug', session_id = 123)\n",
    "#compare models using OOP\n",
    "MejorModelo = ClassExperiment.compare_models(sort = 'Accuracy', n_select = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Evaluation Metrics:\n",
      "Confusion Matrix:\n",
      "+---------+---------+---------+---------+---------+\n",
      "|   drugA |   drugB |   drugC |   drugX |   drugY |\n",
      "+=========+=========+=========+=========+=========+\n",
      "|       2 |       0 |       0 |       0 |       1 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       2 |       0 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       2 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       6 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       0 |       7 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      0.67      0.80         3\n",
      "       drugB       1.00      1.00      1.00         2\n",
      "       drugC       0.00      0.00      0.00         2\n",
      "       drugX       0.75      1.00      0.86         6\n",
      "       drugY       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.72      0.73      0.72        20\n",
      "weighted avg       0.78      0.85      0.80        20\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Logistic Regression Evaluation Metrics:\n",
      "Confusion Matrix:\n",
      "+---------+---------+---------+---------+---------+\n",
      "|   drugA |   drugB |   drugC |   drugX |   drugY |\n",
      "+=========+=========+=========+=========+=========+\n",
      "|       3 |       0 |       0 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       2 |       0 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       1 |       1 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       6 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       0 |       7 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         3\n",
      "       drugB       1.00      1.00      1.00         2\n",
      "       drugC       1.00      0.50      0.67         2\n",
      "       drugX       0.86      1.00      0.92         6\n",
      "       drugY       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.97      0.90      0.92        20\n",
      "weighted avg       0.96      0.95      0.94        20\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Decision Tree Evaluation Metrics:\n",
      "Confusion Matrix:\n",
      "+---------+---------+---------+---------+---------+\n",
      "|   drugA |   drugB |   drugC |   drugX |   drugY |\n",
      "+=========+=========+=========+=========+=========+\n",
      "|       2 |       0 |       0 |       1 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       2 |       0 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       2 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       5 |       1 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       1 |       1 |       0 |       1 |       4 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.67      0.67      0.67         3\n",
      "       drugB       0.67      1.00      0.80         2\n",
      "       drugC       1.00      1.00      1.00         2\n",
      "       drugX       0.71      0.83      0.77         6\n",
      "       drugY       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.77      0.81      0.78        20\n",
      "weighted avg       0.76      0.75      0.74        20\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Support Vector Machine Evaluation Metrics:\n",
      "Confusion Matrix:\n",
      "+---------+---------+---------+---------+---------+\n",
      "|   drugA |   drugB |   drugC |   drugX |   drugY |\n",
      "+=========+=========+=========+=========+=========+\n",
      "|       2 |       0 |       0 |       0 |       1 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       2 |       0 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       2 |       0 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       6 |       0 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "|       0 |       0 |       0 |       0 |       7 |\n",
      "+---------+---------+---------+---------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      0.67      0.80         3\n",
      "       drugB       1.00      1.00      1.00         2\n",
      "       drugC       1.00      1.00      1.00         2\n",
      "       drugX       1.00      1.00      1.00         6\n",
      "       drugY       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.97      0.93      0.95        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/drugs_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/drugs_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/drugs_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "# Initializing a dictionary to store evaluation metrics\n",
    "model_evaluation_metrics = {}\n",
    "\n",
    "# Iterating over each model to evaluate\n",
    "for model_name, model in models.items():\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    # Calculate confusion matrix and classification report\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    classif_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Storing the results\n",
    "    model_evaluation_metrics[model_name] = {\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': classif_report\n",
    "    }\n",
    "\n",
    "    # Outputting the results for review\n",
    "    print(f\"{model_name} Evaluation Metrics:\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(tabulate(conf_matrix, headers=model.classes_, tablefmt='grid'))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classif_report)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
